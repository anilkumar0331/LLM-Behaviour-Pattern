## LARGE LANGUAGE MODEL BEHAVIOR PATTERN IN DEFINED TEXT OUTPUT

**Organization:**	[Human-Cyber Performance Tech, LLC](https://www.human-cyber-performance-tech.com/)

**Project POC(s):**	Dr. Curt Rasmussen, Lead Researcher, rasmussenc@outlook.com


### Problem Statement
   - Large Language Models (LLMs) such as **ChatGPT** and **Gemini** are producing few inaccurate (termed as hallucinations) responses and lack consistency.
   - Assess and develop methods using Natural Language Processing (NLP) to evaluate these **hallucinations** and **inconsistencies**.
   - Investigate the existence of **pattern behaviour** related to hallucinations and consistency across the responses of these LLM models.

### Method to assess hallucinations patterns
Used [GPT Responses Corpus](https://data.mendeley.com/datasets/wfmj9bknd7/1) dataset to find hallucinations and its pattern behaviour.
#### Steps performed:

**1) Data Cleaning** - `LLM Hallucinations/data_cleaning.ipynb`
   - Removes unnecessary columns and filters questions by length from the original dataset `GPTRC_GPT_Responses_Corpus.xlsx`.
   - Separates questions into categories like numbered, mathematical, logical, opinion-based, and subjective.
   - Further identifies facual questions from the dataset.
   - Stores categorized questions in text files and writes the filtered factual questions dataset back to an Excel file `filtered_gptrc_data.xlsx`.

**2) Web Searching** - `LLM Hallucinations/web_searching.ipynb`
   - Read the data from `filtered_gptrc_data.xlsx` containing questions into a pandas DataFrame.
   - Use the Bing Search API to fetch web search results for each question. Each question is sent as a query to the API, and the top 5 URLs from the search results are collected.
   - The questions along with their corresponding URLs are stored in a JSON file named `gptrc_urls.json`.

**3) Web Scraping** - `LLM Hallucinations/web_scraping.ipynb`
   - From `gptrc_urls.json`, filters URLs associated with each question based on a list of reliable domains. This helps ensure the credibility of the source information.
   - Stores the filtered URLs into JSON file `gptrc_reliable_urls.json` and removes any entries without associated URLs and then store in `gptrc_reliable_urls_filtered.json`.
   - Uses multi-threading to fetch, clean, and compile substantial text content from reliable URLs, associating it with the original questions.
   - Removes entries where no useful information was fetched, ensuring the dataset only includes valid and substantial data.
   - Saves the final structured data with questions, URLs, and extracted text into a JSON file `gptrc_urls_context.json`.

**4) Hallucinations** - `LLM Hallucinations/hallucinations.ipynb`
   - Reads questions from `gptrc_urls_context.json`, merges this data with corresponding answers from `filtered_gptrc_data.xlsx`, and stores the combined dataset in `gptrc_urls_context_with_llm_answers.json`.
   - Utilizes a [Gradio client](https://huggingface.co/spaces/fava-uw/fava) to compare LLM answers against the text extracted from web pages to detect hallucinations (inaccurate information generated by the LLM). The results are stored in `hallucinations.json`.
   - Filters out entries with no meaningful hallucination detection results, storing the cleaned data in `hallucinations_filtered.json`.

**5) Hallucination Patterns** - `LLM Hallucinations/Hallucination_Patterns/hallucinations_patterns.ipynb`
   - Reads hallucination data from `hallucinations_filtered.json` where each entry includes a question, a reference URL, and results indicating if the LLM's answer contained hallucinations.
   - Classifies hallucinations into distinct categories based on predefined HTML pattern tags that denote different types of inaccuracies, such as 'invented', 'subjective', 'entity', etc. It checks each hallucination result for these tags and categorizes them accordingly.
   - Stores categorized hallucinations in separate files:
      1. `factual_inaccuracy_and_misclassification_hallucinations.json` for errors related to factual inaccuracies and misclassifications.
      2. `fabricated_detail_hallucinations.json` for entirely fabricated details.
      3. `speculative_reasoning_hallucinations.json` for speculative reasoning errors.
      4. `all_four_patterns_hallucinations.json` for responses containing multiple error types.
      5. `miscellaneous_hallucinations.json` for other detected patterns needing further analysis.
      6. `no_hallucinations.json` for responses with no detected inaccuracies.


### Method to assess consistency patterns
Used [Wiki Bio GPT3 Hallucination](https://huggingface.co/datasets/potsawee/wiki_bio_gpt3_hallucination) dataset to find consistency among query responses and its pattern behaviour.
#### Steps performed:

**1) Data Cleaning** - `LLM Consistency/data_cleaning.ipynb`
   - Imports data from `wiki_bio_gpt3.json`, detailing Wiki biography texts and GPT-3 responses.
   - Removes unnecessary attributes from the data entries, such as 'gpt3_text', 'gpt3_sentences', 'annotation', and 'wiki_bio_test_idx'.
   - Limits 'gpt3_text_samples' to the first three entries for each record to streamline content.
   - Exports the refined dataset to `wiki_bio_gpt3_filtered.json`.

**2) Consistency** - `LLM Consistency/consistency.ipynb`
   - Imports cleaned Wiki biography text data with corresponding GPT-3 generated samples from `wiki_bio_gpt3_filtered.json`.
   - Initializes an NLP tokenizer and model (sentence-transformers/all-MiniLM-L6-v2) for text embedding.
   - Computes cosine similarity matrices for GPT-3 text samples to assess their mutual similarity, using the embeddings generated by the NLP model.
   - Applies the similarity calculations to each entry in the dataset and computes the average similarity scores for these samples.
   - Sorts the entries based on average similarity scores and saves the processed data to `wiki_bio_gpt3_with_similariy_scores.json`.

**3) Manual Evaluation:** - `LLM Consistency/consistency.html`
   - Use html file that includes JavaScript code to dynamically load and display data from `wiki_bio_gpt3_with_similariy_scores.json` on a web page and save it `consistency_evaluation.html`.
   - Perform the manual evaluation on `consistency_evaluation.html` and find the pattern behaviour of consistency among multiple query responses.

### Acknowledgement
This repo wouldn't be possible without the awesome [GPT Responses Corpus](https://data.mendeley.com/datasets/wfmj9bknd7/1), [Wiki Bio GPT3 Hallucination](https://huggingface.co/datasets/potsawee/wiki_bio_gpt3_hallucination), and [Gradio client](https://huggingface.co/spaces/fava-uw/fava).
